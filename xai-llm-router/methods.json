{
  "toolkits": [
    {
      "name": "Captum",
      "task_input": [
        "general_NLP",
        "classification",
        "NA"
      ],
      "access_arch": {
        "access": [
          "white_box"
        ],
        "arch": [
          "transformer_general",
          "NA"
        ]
      },
      "target_scope": "both",
      "granularity": [
        "token",
        "neuron",
        "layer"
      ],
      "user_goal_audience": [
        "research_debug",
        "general_tooling"
      ],
      "fidelity": "medium",
      "format": [
        "notebook_viz",
        "API_only"
      ],
      "notes": "Attribution methods: primary attribution, layer attribution, neuron attribution."
    },
    {
      "name": "InterpretML",
      "task_input": [
        "general_NLP",
        "NA"
      ],
      "access_arch": {
        "access": [
          "black_box",
          "white_box",
          "mixed"
        ],
        "arch": [
          "non_llm",
          "NA"
        ]
      },
      "target_scope": "both",
      "granularity": [
        "dataset",
        "NA"
      ],
      "user_goal_audience": [
        "general_tooling",
        "model_eval"
      ],
      "fidelity": "medium",
      "format": [
        "API_only",
        "metrics"
      ],
      "notes": "Classic post-hoc methods: SHAP, LIME, partial dependence plots, Morris sensitivity analysis."
    },
    {
      "name": "Alibi",
      "task_input": [
        "general_NLP",
        "classification",
        "NA"
      ],
      "access_arch": {
        "access": [
          "black_box",
          "mixed"
        ],
        "arch": [
          "transformer_general",
          "NA"
        ]
      },
      "target_scope": "both",
      "granularity": [
        "token",
        "span",
        "example",
        "rules",
        "NA"
      ],
      "user_goal_audience": [
        "general_tooling",
        "end_user_explain"
      ],
      "fidelity": "mixed",
      "format": [
        "API_only",
        "rules",
        "ranked_examples",
        "NA"
      ],
      "notes": "Broader XAI: ALE, permutation importance, pertinent positives, counterfactuals; text methods include Anchors, IG, similarity explanations."
    },
    {
      "name": "Dalex",
      "task_input": [
        "tabular_only"
      ],
      "access_arch": {
        "access": [
          "black_box",
          "mixed"
        ],
        "arch": [
          "non_llm"
        ]
      },
      "target_scope": "both",
      "granularity": [
        "dataset"
      ],
      "user_goal_audience": [
        "model_eval",
        "fairness_audit"
      ],
      "fidelity": "medium",
      "format": [
        "API_only",
        "metrics"
      ],
      "notes": "Explainability + fairness; supports tabular data only."
    },
    {
      "name": "FAT Forensics",
      "task_input": [
        "tabular_only"
      ],
      "access_arch": {
        "access": [
          "black_box",
          "mixed"
        ],
        "arch": [
          "non_llm"
        ]
      },
      "target_scope": "both",
      "granularity": [
        "dataset"
      ],
      "user_goal_audience": [
        "fairness_audit",
        "model_eval"
      ],
      "fidelity": "medium",
      "format": [
        "API_only",
        "metrics"
      ],
      "notes": "Fairness/accountability/transparency toolbox; focusing on tabular data."
    },
    {
      "name": "Amazon SageMaker Clarify",
      "task_input": [
        "general_NLP",
        "tabular_only",
        "NA"
      ],
      "access_arch": {
        "access": [
          "mixed"
        ],
        "arch": [
          "non_llm",
          "transformer_general",
          "NA"
        ]
      },
      "target_scope": "both",
      "granularity": [
        "dataset",
        "NA"
      ],
      "user_goal_audience": [
        "fairness_audit",
        "model_eval"
      ],
      "fidelity": "medium",
      "format": [
        "API_only",
        "metrics"
      ],
      "notes": "AWS tool for fairness + explainability; includes SHAP and PDP."
    },
    {
      "name": "PnPXAI",
      "task_input": [
        "multimodal",
        "general_NLP"
      ],
      "access_arch": {
        "access": [
          "mixed",
          "NA"
        ],
        "arch": [
          "transformer_general",
          "non_llm",
          "NA"
        ]
      },
      "target_scope": "both",
      "granularity": [
        "dataset",
        "NA"
      ],
      "user_goal_audience": [
        "general_tooling",
        "end_user_explain"
      ],
      "fidelity": "mixed",
      "format": [
        "API_only",
        "NA"
      ],
      "notes": "Auto-detects architecture, recommends explainers for data type, can optimize explainer hyperparameters."
    },
    {
      "name": "EXPLAINABOARD",
      "task_input": [
        "general_NLP"
      ],
      "access_arch": {
        "access": [
          "NA"
        ],
        "arch": [
          "NA"
        ]
      },
      "target_scope": "global",
      "granularity": [
        "dataset"
      ],
      "user_goal_audience": [
        "model_eval"
      ],
      "fidelity": "NA",
      "format": [
        "visual_UI",
        "metrics"
      ],
      "notes": "Leaderboard emphasizing interpretability, interactivity, reliability of evaluation (as described)."
    },
    {
      "name": "Alibi (text explainers)",
      "task_input": [
        "classification"
      ],
      "access_arch": {
        "access": [
          "mixed"
        ],
        "arch": [
          "transformer_general",
          "NA"
        ]
      },
      "target_scope": "local",
      "granularity": [
        "token",
        "span",
        "rules",
        "example"
      ],
      "user_goal_audience": [
        "general_tooling",
        "end_user_explain"
      ],
      "fidelity": "mixed",
      "format": [
        "rules",
        "ranked_examples",
        "API_only"
      ],
      "notes": "Text explainers: Anchors (rule-based), Integrated Gradients, similarity explanations (nearest training examples)."
    },
    {
      "name": "ferret",
      "task_input": [
        "classification"
      ],
      "access_arch": {
        "access": [
          "mixed"
        ],
        "arch": [
          "transformer_general"
        ]
      },
      "target_scope": "local",
      "granularity": [
        "token",
        "span"
      ],
      "user_goal_audience": [
        "research_debug",
        "model_eval"
      ],
      "fidelity": "mixed",
      "format": [
        "API_only",
        "metrics",
        "notebook_viz"
      ],
      "notes": "Transformers text classification explainers (gradients, IG, SHAP, LIME) + faithfulness/plausibility metrics + benchmark datasets."
    },
    {
      "name": "transformers-interpret",
      "task_input": [
        "classification",
        "QA",
        "NER"
      ],
      "access_arch": {
        "access": [
          "white_box",
          "mixed"
        ],
        "arch": [
          "transformer_general"
        ]
      },
      "target_scope": "local",
      "granularity": [
        "token"
      ],
      "user_goal_audience": [
        "general_tooling",
        "research_debug"
      ],
      "fidelity": "medium",
      "format": [
        "API_only"
      ],
      "notes": "Convenient attribution scores for HF Transformers; tasks include classification, QA, NER (as described)."
    },
    {
      "name": "Captum v0.7",
      "task_input": [
        "generation",
        "seq2seq"
      ],
      "access_arch": {
        "access": [
          "mixed"
        ],
        "arch": [
          "decoder",
          "encdec",
          "transformer_general"
        ]
      },
      "target_scope": "local",
      "granularity": [
        "token"
      ],
      "user_goal_audience": [
        "research_debug",
        "general_tooling"
      ],
      "fidelity": "mixed",
      "format": [
        "notebook_viz",
        "API_only"
      ],
      "notes": "Extends attribution to text generation; prompt token → generated token impact via perturbation- and gradient-based approaches; includes visualization utilities."
    },
    {
      "name": "Inseq",
      "task_input": [
        "generation",
        "seq2seq"
      ],
      "access_arch": {
        "access": [
          "mixed"
        ],
        "arch": [
          "decoder",
          "encdec"
        ]
      },
      "target_scope": "local",
      "granularity": [
        "token"
      ],
      "user_goal_audience": [
        "research_debug",
        "general_tooling"
      ],
      "fidelity": "mixed",
      "format": [
        "API_only",
        "notebook_viz"
      ],
      "notes": "Builds on Captum for attribution in generation; target sequence or generated sequence; includes discretized IG and attention-based attribution."
    },
    {
      "name": "Interpret-Text",
      "task_input": [
        "classification",
        "generation"
      ],
      "access_arch": {
        "access": [
          "mixed"
        ],
        "arch": [
          "encoder",
          "NA"
        ]
      },
      "target_scope": "both",
      "granularity": [
        "token",
        "span",
        "layer",
        "dataset"
      ],
      "user_goal_audience": [
        "research_debug",
        "general_tooling"
      ],
      "fidelity": "mixed",
      "format": [
        "API_only"
      ],
      "notes": "Built on InterpretML; includes BERT intermediate-layer information-based explainer, selective rationalization, and perturbation-based explainers."
    },
    {
      "name": "INTERPRETO",
      "task_input": [
        "classification",
        "generation"
      ],
      "access_arch": {
        "access": [
          "mixed"
        ],
        "arch": [
          "transformer_general",
          "NA"
        ]
      },
      "target_scope": "both",
      "granularity": [
        "token",
        "concept",
        "dataset",
        "NA"
      ],
      "user_goal_audience": [
        "research_debug",
        "general_tooling"
      ],
      "fidelity": "mixed",
      "format": [
        "API_only"
      ],
      "notes": "Unified API; perturbation- and gradient-based attributions + concept-based explanations."
    },
    {
      "name": "AllenNLP Interpret",
      "task_input": [
        "classification",
        "QA",
        "NER",
        "general_NLP"
      ],
      "access_arch": {
        "access": [
          "white_box",
          "mixed"
        ],
        "arch": [
          "transformer_general",
          "NA"
        ]
      },
      "target_scope": "local",
      "granularity": [
        "token",
        "span",
        "example"
      ],
      "user_goal_audience": [
        "research_debug"
      ],
      "fidelity": "medium",
      "format": [
        "API_only",
        "notebook_viz"
      ],
      "notes": "Gradients + adversarial attacks to generate counterfactuals/exemplars; supports multiple NLP tasks."
    },
    {
      "name": "LIT (Language Interpretability Tool)",
      "task_input": [
        "general_NLP",
        "classification",
        "generation"
      ],
      "access_arch": {
        "access": [
          "mixed"
        ],
        "arch": [
          "transformer_general",
          "NA"
        ]
      },
      "target_scope": "both",
      "granularity": [
        "token",
        "dataset",
        "example"
      ],
      "user_goal_audience": [
        "research_debug",
        "model_eval"
      ],
      "fidelity": "mixed",
      "format": [
        "visual_UI"
      ],
      "notes": "Browser-based; salience maps, embedding visualizations, counterfactual generation, interactive exploration; supports custom models/datasets; not LLM-specific."
    },
    {
      "name": "ECCO",
      "task_input": [
        "general_NLP",
        "generation",
        "seq2seq"
      ],
      "access_arch": {
        "access": [
          "white_box",
          "mixed"
        ],
        "arch": [
          "decoder",
          "encdec"
        ]
      },
      "target_scope": "both",
      "granularity": [
        "token",
        "neuron",
        "layer",
        "dataset",
        "concept",
        "NA"
      ],
      "user_goal_audience": [
        "research_debug",
        "mech_interp"
      ],
      "fidelity": "medium",
      "format": [
        "visual_UI",
        "notebook_viz"
      ],
      "notes": "Input attribution (Grad×Input), hidden-state evolution (CCA, logit lens), neuron inspection (NMF, probing classifiers)."
    },
    {
      "name": "LLMCheckup",
      "task_input": [
        "general_NLP",
        "QA",
        "NA"
      ],
      "access_arch": {
        "access": [
          "mixed"
        ],
        "arch": [
          "decoder",
          "transformer_general",
          "NA"
        ]
      },
      "target_scope": "both",
      "granularity": [
        "token",
        "example",
        "dataset",
        "NA"
      ],
      "user_goal_audience": [
        "end_user_explain",
        "research_debug"
      ],
      "fidelity": "mixed",
      "format": [
        "interactive_dialogue"
      ],
      "notes": "Conversational examination; integrates internal-access methods (feature attribution, semantic similarity) plus prompting-based rationalization/counterfactuals without internals."
    },
    {
      "name": "TransformerLens",
      "task_input": [
        "general_NLP",
        "NA"
      ],
      "access_arch": {
        "access": [
          "white_box"
        ],
        "arch": [
          "transformer_general"
        ]
      },
      "target_scope": "both",
      "granularity": [
        "head",
        "neuron",
        "layer",
        "circuit",
        "component_graph"
      ],
      "user_goal_audience": [
        "mech_interp",
        "research_debug"
      ],
      "fidelity": "high",
      "format": [
        "API_only",
        "notebook_viz"
      ],
      "notes": "Hooks on modules; capture activations/gradients; activation+path patching; logit/attention lenses; IOI-style analyses."
    },
    {
      "name": "MechaMap",
      "task_input": [
        "general_NLP"
      ],
      "access_arch": {
        "access": [
          "white_box"
        ],
        "arch": [
          "transformer_general"
        ]
      },
      "target_scope": "global",
      "granularity": [
        "neuron",
        "layer"
      ],
      "user_goal_audience": [
        "mech_interp",
        "research_debug"
      ],
      "fidelity": "medium",
      "format": [
        "API_only"
      ],
      "notes": "Identifies neurons/groups that activate for a semantic feature; used to locate domain-specific signals."
    },
    {
      "name": "sae-lens",
      "task_input": [
        "general_NLP"
      ],
      "access_arch": {
        "access": [
          "white_box"
        ],
        "arch": [
          "transformer_general"
        ]
      },
      "target_scope": "both",
      "granularity": [
        "concept",
        "neuron",
        "layer"
      ],
      "user_goal_audience": [
        "mech_interp",
        "research_debug"
      ],
      "fidelity": "high",
      "format": [
        "API_only",
        "notebook_viz"
      ],
      "notes": "Sparse autoencoders on activations; inspect features and do causal evaluation via ablation/patching."
    },
    {
      "name": "BertViz",
      "plugin_id": "bertviz_attention",
      "task_input": [
        "general_NLP"
      ],
      "access_arch": {
        "access": [
          "white_box",
          "gray_box"
        ],
        "arch": [
          "encoder",
          "encdec",
          "decoder"
        ]
      },
      "target_scope": "local",
      "granularity": [
        "head",
        "token",
        "layer"
      ],
      "user_goal_audience": [
        "research_debug"
      ],
      "fidelity": "low",
      "format": [
        "visual_UI"
      ],
      "notes": "Attention visualization; model view + neuron view; attention-only explanations can be misleading."
    },
    {
      "name": "exBERT",
      "task_input": [
        "general_NLP"
      ],
      "access_arch": {
        "access": [
          "white_box",
          "gray_box"
        ],
        "arch": [
          "encoder",
          "NA"
        ]
      },
      "target_scope": "local",
      "granularity": [
        "head",
        "token",
        "layer"
      ],
      "user_goal_audience": [
        "research_debug"
      ],
      "fidelity": "low",
      "format": [
        "visual_UI"
      ],
      "notes": "Interprets attention patterns while also considering attended-to embeddings; works on user-defined model and corpus."
    },
    {
      "name": "LM-Debugger",
      "task_input": [
        "general_NLP",
        "NA"
      ],
      "access_arch": {
        "access": [
          "white_box"
        ],
        "arch": [
          "transformer_general"
        ]
      },
      "target_scope": "local",
      "granularity": [
        "layer",
        "neuron",
        "component_graph"
      ],
      "user_goal_audience": [
        "mech_interp",
        "research_debug"
      ],
      "fidelity": "high",
      "format": [
        "visual_UI",
        "NA"
      ],
      "notes": "Layer-wise interpretation with FFN sub-updates projected to vocab; targeted interventions; index of FFN vectors."
    },
    {
      "name": "LM Transparency Tool (LM-TT)",
      "task_input": [
        "general_NLP"
      ],
      "access_arch": {
        "access": [
          "white_box"
        ],
        "arch": [
          "transformer_general"
        ]
      },
      "target_scope": "both",
      "granularity": [
        "head",
        "neuron",
        "layer",
        "component_graph"
      ],
      "user_goal_audience": [
        "mech_interp",
        "research_debug"
      ],
      "fidelity": "high",
      "format": [
        "visual_UI"
      ],
      "notes": "Highlights important input→output information flow; component attribution from heads to neurons; uses logit lens/update projection; includes attention visualizations."
    },
    {
      "name": "VISIT",
      "task_input": [
        "general_NLP"
      ],
      "access_arch": {
        "access": [
          "white_box"
        ],
        "arch": [
          "transformer_general"
        ]
      },
      "target_scope": "local",
      "granularity": [
        "neuron",
        "layer",
        "component_graph"
      ],
      "user_goal_audience": [
        "mech_interp",
        "research_debug"
      ],
      "fidelity": "high",
      "format": [
        "visual_UI"
      ],
      "notes": "Interactive flow graph of forward pass; logit lens projections for hidden states and neuron activations."
    },
    {
    "name": "Captum (classifier attribution)",
    "plugin_id": "captum_classifier",
    "task_input": ["classification"],
    "access_arch": {"access": "white_box", "arch": "transformer_general"},
    "target_scope": "local",
    "granularity": ["token"],
    "format": ["visual_UI"],
    "fidelity": "high",
    "notes": "Generic Captum attribution for HF sequence classifiers (IG/Saliency/DeepLift)."
   }, 
   {
  "name": "Logit Lens (HF-native)",
  "plugin_id": "logit_lens",
  "task_input": ["generation", "seq2seq", "general_NLP", "NA"],
  "access_arch": {
    "access": ["white_box"],
    "arch": ["decoder", "encdec", "transformer_general", "NA"]
  },
  "target_scope": "local",
  "granularity": ["layer", "token"],
  "user_goal_audience": ["mech_interp", "research_debug", "general_tooling"],
  "fidelity": "medium",
  "format": ["visual_UI", "API_only"],
  "notes": "Layer-wise vocab projection (logit lens) implemented directly with Hugging Face models: hidden states → (optional final norm) → lm_head → top-k tokens."
}
  ]
}



